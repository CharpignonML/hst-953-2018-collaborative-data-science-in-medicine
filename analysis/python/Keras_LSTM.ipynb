{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cleaner_Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "JuinrXO4TZOb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# From Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ax2KO0DTeF0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load train and validation sets (both X and Y)\n",
        "X_train_template = \"/content/drive/My Drive/train/X_tensor_train_chunk_\"\n",
        "Y_train_template = \"/content/drive/My Drive/train/Y_tensor_train_chunk_\"\n",
        "\n",
        "X_val_template = \"/content/drive/My Drive/val/X_tensor_val_chunk_\"\n",
        "Y_val_template = \"/content/drive/My Drive/val/Y_tensor_val_chunk_\"\n",
        "\n",
        "suffix = \".pkl\"\n",
        "\n",
        "minimum = 0\n",
        "cut_1 = 33000\n",
        "cut_2 = 40000\n",
        "maximum = 100000\n",
        "step = 1000\n",
        "\n",
        "def partial_list(X_template,Y_template,left,right,step):\n",
        "  return([ [X_template+str(chunk)+suffix, Y_template+str(chunk)+suffix] for chunk in range(left,right,step)])\n",
        "\n",
        "# part 1: subject id 3 to 32811 (>= 0 and < 33000 in practice)\n",
        "np_train_list_part1 = partial_list(X_train_template,Y_train_template,minimum,cut_1,step)\n",
        "np_val_list_part1 = partial_list(X_val_template,Y_val_template,minimum,cut_1,step)\n",
        "\n",
        "# part 2: subject id >= 40000\n",
        "np_train_list_part2 = partial_list(X_train_template,Y_train_template,cut_2,maximum,step)\n",
        "np_val_list_part2 = partial_list(X_val_template,Y_val_template,cut_2,maximum,step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nm4eHyjJx2Jh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# p Try to release memory\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "from keras.backend.tensorflow_backend import clear_session\n",
        "from keras.backend.tensorflow_backend import get_session\n",
        "import tensorflow\n",
        "\n",
        "# Reset Keras Session\n",
        "def reset_keras():\n",
        "    sess = get_session()\n",
        "    clear_session()\n",
        "    sess.close()\n",
        "    sess = get_session()\n",
        "\n",
        "    try:\n",
        "        del classifier # this is from global space - change this as you need\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    #print(gc.collect()) # if it's done something you should see a number being outputted\n",
        "\n",
        "    # use the same config as you used to create the session\n",
        "    config = tensorflow.ConfigProto()\n",
        "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
        "    config.gpu_options.visible_device_list = \"0\"\n",
        "    set_session(tensorflow.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQi0ltjlTiNt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Method that concatenates all the X's and all the Y's from a given list into\n",
        "# an overall tuple\n",
        "import numpy as np\n",
        "\n",
        "def concat(np_list):\n",
        "  \n",
        "  x_final = np.load(np_list[0][0])[:,:,4:]\n",
        "  y_final = np.load(np_list[0][1])[:,]\n",
        "  \n",
        "  for e in range(1,len(np_list)):\n",
        "    x_final = np.concatenate((x_final, np.load(np_list[e][0])[:,:,4:]),axis=0)\n",
        "    y_final = np.concatenate((y_final, np.load(np_list[e][1])[:,]),axis=0)\n",
        "    \n",
        "  print(x_final.shape)\n",
        "  print(y_final.shape)\n",
        "  \n",
        "  return(x_final,y_final)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eiB-f461TmAv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "x_train,y_train = concat(np_train_list_part1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NoCzzNz3TooA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_val,y_val = concat(np_val_list_part1)\n",
        "x_val2,y_val2 = concat(np_val_list_part2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yEPDbm47TrFO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train2,y_train2 = concat(np_train_list_part2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6lPma5CQTtmx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.concatenate((x_train,x_train2),axis=0)\n",
        "#y_train = np.concatenate((y_train,y_train2),axis=0)\n",
        "#print(x_train.shape)\n",
        "#print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HRaeTAC8Txj0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential # needed to activate NN\n",
        "from keras.layers import Dense, LSTM, Dropout # needed to add hidden layers (of three types in our case)\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import keras.optimizers\n",
        "import keras.regularizers\n",
        "import sys\n",
        "!pip install keras_metrics # (you will need to install this package)\n",
        "import keras_metrics\n",
        "\n",
        "# Fixed parameters \n",
        "timesteps = 6 # duration of a slice\n",
        "data_dim = 66 # number of features\n",
        "\n",
        "def build_model(dimension_list, dropout_list,timesteps=6,data_dim=66, reg_param=0.001):\n",
        "  \n",
        "  model = Sequential()\n",
        "  # ANU\n",
        "  model.add(Dense(dimension_list[0], activation='relu',init='uniform', kernel_regularizer=keras.regularizers.l2(reg_param), input_shape=(timesteps, data_dim)))\n",
        "  # ALDO\n",
        "  #model.add(Dense(dimension_list[0], activation='relu',init='uniform', kernel_regularizer=keras.regularizers.l1(reg_param), input_shape=(timesteps, data_dim)))\n",
        "  \n",
        "  for i in range(1,len(dimension_list)-1):\n",
        "    model.add(LSTM(dimension_list[i], return_sequences=True)) # returns a sequence of vectors of dimension \"dim_i\"\n",
        "    model.add(Dropout(dropout_list[i-1]))\n",
        "    \n",
        "  model.add(LSTM(dimension_list[len(dimension_list)-1]))\n",
        "  model.add(Dropout(dropout_list[len(dropout_list)-1]))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  \n",
        "  return(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o07RT4VkT1Cd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Pick a model of your choice\n",
        "\n",
        "dimension_choice = [512,512,512] # Harini had 512 twice, but here we are adding a dense layer first\n",
        "dropout_choice = [0.3,0.3,0.3] # between 0.2 and 0.5\n",
        "\n",
        "def model_name(dimension_choice,dropout_choice):\n",
        "  \n",
        "  dimension_choice_str = [str(e) for e in dimension_choice]\n",
        "  dropout_choice_str = [str(int(e*100)) for e in dropout_choice]\n",
        "\n",
        "  model_name = str(len(dimension_choice)) + \"_dim_\" + \"_\".join(dimension_choice_str) + \"_drop_\" + \"_\".join(dropout_choice_str)\n",
        "  \n",
        "  return(model_name)\n",
        "\n",
        "model = build_model(dimension_choice, dropout_choice)\n",
        "model_name = model_name(dimension_choice, dropout_choice)\n",
        "\n",
        "proba_threshold = 0.5\n",
        "\n",
        "# Compile it\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = [keras_metrics.recall()])\n",
        "                                                                           #,keras_metrics.precision(),auc_roc,'accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F3wjtIguT3iV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save the model weights after each epoch if the validation loss decreased\n",
        "data_path = '/content/drive/My Drive'\n",
        "checkpointer = ModelCheckpoint(filepath=data_path + '/model_new_' + model_name +'_{epoch:02d}.hdf5', verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zjd9VsrPT7Wm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Determine class weights\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
        "print(class_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i9JtfPXgT9RF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class_weight = {0: class_weights[0],\n",
        "                1: class_weights[1]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7QcWuh4dT_2Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fit the model based on rebalanced dataset\n",
        "\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "min_delta = 0.0001\n",
        "patience = 3\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs, class_weight=class_weight, verbose=1, validation_data=(x_val,y_val), callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=min_delta, patience=patience, verbose=1, mode='auto'), checkpointer])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LRLOopHQUEdu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load test set\n",
        "\n",
        "X_test_template = \"/content/drive/My Drive/test/X_tensor_test_chunk_\"\n",
        "Y_test_template = \"/content/drive/My Drive/test/Y_tensor_test_chunk_\"\n",
        "\n",
        "np_test_list_part1 = partial_list(X_test_template,Y_test_template,minimum,cut_1,step)\n",
        "np_test_list_part2 = partial_list(X_test_template,Y_test_template,cut_2,maximum,step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jOXqIteUUIJZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test1,y_test1 = concat(np_test_list_part1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-utKQ3_MUMOW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test2,y_test2 = concat(np_test_list_part2)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-unSOJ05UMzU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test = np.concatenate((x_test1,x_test2),axis=0)\n",
        "y_test=np.concatenate((y_test1,y_test2),axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RgsHfFVXUTb-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "def recall(x_test,y_test,model,batch_size):\n",
        "  evaluation = model.evaluate(x_test,y_test,batch_size=batch_size)\n",
        "  recall = evaluation[1]\n",
        "  return(recall)\n",
        "\n",
        "print(recall(x_test,y_test,model,batch_size))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}